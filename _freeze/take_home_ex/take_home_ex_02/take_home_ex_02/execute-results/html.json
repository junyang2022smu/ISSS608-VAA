{
  "hash": "7340f8a2242201f3d025ef34d815eccf",
  "result": {
    "markdown": "---\ntitle: \"Take-Home Exercise 2: VAST Challenge 2023, Mini-Challenge 2\"\nauthor: \"Yang Jun\"\ndate: 14 May 2023\ndate-modified: \"2023-06-05\"\nexecute:\n  echo: true\n  eval: true\n  warning: false\nnumber-sections: true\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show Code\"\n---\n\n\nThis take-home exercise is based on [VAST Challenge 2023's Mini-Challenge 2](https://vast-challenge.github.io/2023/MC2.html).\n\n# The Brief\n\n## Setting the Scene\n\n*The following text is lifted from the Challenge webpage. Emphases are my own.*\n\nThe country of Oceanus has sought FishEye International's help in identifying companies possibly engaged in **illegal, unreported, and unregulated (IUU) fishing**. As part of the collaboration, FishEye's analysts received **import/export data for Oceanus' marine and fishing industries**. However, Oceanus has informed FishEye that the data is incomplete. To facilitate their analysis, FishEye transformed the trade data into a **knowledge graph**. Using this knowledge graph, they hope to understand **business relationships**, including finding links that will help them stop IUU fishing and protect marine species that are affected by it. FishEye analysts found that node-link diagrams gave them a good high-level overview of the knowledge graph. However, they are now looking for visualizations that provide more detail about patterns for entities in the knowledge graph. There are two main parts to this analysis.\n\nFirst, FishEye knows from past experience that companies caught fishing illegally will shut down but will then often start up again under a different name. FishEye wants your help to **visualize temporal patterns so they can compare the activities of companies over time** to determine if the companies have returned to their nefarious acts.\n\nSecond, FishEye has been using several tools, including artificial intelligence, to reason on the knowledge graph and suggest **links that could extend the dataset**. They have supplied 12 groups of link suggestions and need your help evaluating these groups to identify which tools are most reliable for completing the graph. FishEye is especially interested in identifying **new temporal patterns or anomalies that are only present when new links are added.**\n\nUsing visual analytics, can you help FishEye identify companies that may be engaged in illegal fishing?\n\n## The Task\n\nUsing appropriate **static and interactive statistical graphics** methods, help FishEye identify companies that may be engaged in illegal fishing, by answering **one** of the following four questions listed on the Mini-Challenge 2 webpage:\n\n1.  Use visual analytics to identify **temporal patterns for individual entities and between entities** in the knowledge graph FishEye created from trade records. Categorize the types of business relationship patterns you find.\n\n2.  Evaluate the sets of predicted knowledge graph links FishEye has provided using visual analytics. Which sets are most **reliable** for completing the graph?\n\n3.  Illustrate how your visual analytics approach can be used to **identify new patterns and/or anomalies** that are present in the knowledge graph after you have added the links you deemed reliable in question 2.\n\n4.  **Identify companies that fit a pattern of illegal fishing**. Use visualizations to support your conclusions and your confidence in them.\n\nI will be attempting the first question:\n\n| Use visual analytics to identify **temporal patterns for individual entities and between entities** in the knowledge graph FishEye created from trade records. Categorize the types of business relationship patterns you find.\n\n# Libraries and Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(jsonlite, readxl, fuzzyjoin, igraph, tidygraph, tidytext, ggraph, ggradar, fmsb, patchwork, GGally, colorspace,\n               visNetwork, lubridate, clock,\n               tidyverse, magrittr, graphlayouts)\n```\n:::\n\n\n# Data Preparation\n\n## Data Overview\n\nAccording to the provided data dictionary, the main graph has **34,552 nodes** and **5,464,092 directed edges** (note: file size \\~1.55GB). Each edge represents a shipment from a shipper to a receiver.\n\n### Node Attributes\n\n| Attribute    | Data Type (assumed) | Description                                                    |\n|-----------------|-----------------|---------------------------------------|\n| `id`         | char                | Name of the company that originated (or received) the shipment |\n| `shpcountry` | char                | Country the company most often associated with when shipping   |\n| `rcvcountry` | char                | Country the company most often associated with when receiving  |\n| `dataset`    | char                | Always 'MC2'                                                   |\n\n### Edge Attributes\n\n| Attribute          | Data Type (assumed) | Description                                                                                                                                                                                                                                                              |\n|-------------|-------------|----------------------------------------------|\n| `arrivaldate`      | date                | Date the shipment arrived at port in YYYY-MM-DD format                                                                                                                                                                                                                   |\n| `hscode`           | char                | Harmonized System code for the shipment. Can be joined with the `hscodes` table to get additional details                                                                                                                                                                |\n| `valueofgoods_omu` | integer             | Customs-declared value of the total shipment, in Oceanus Monetary Units OMU                                                                                                                                                                                              |\n| `volumeteu`        | integer             | The volume of the shipment in 'Twenty-foot equivalent units', roughly how many 20-foot standard containers would be required. Actual number of containers may have been different as there are 20ft and 40ft standard containers and tankers that do not use containers) |\n| `weightkg`         | integer             | The weight of the shipment in kilograms (if known)                                                                                                                                                                                                                       |\n| `dataset`          | char                | Always 'MC2'                                                                                                                                                                                                                                                             |\n| `type`             | char                | Always 'shipment' for MC2                                                                                                                                                                                                                                                |\n| `generated_by`     | char                | Name of the program that generated the edge. (Only found on 'bundle' records)                                                                                                                                                                                            |\n\n## Data Cleaning & Conversion to Graph\n\n### Main Graph\n\nLet's load the main graph JSON data first. (This takes a while due to the size of the file.) Then persist it for faster loading next time.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nif (file.exists('data/mc2.rds')) {\n  MC2 <- read_rds('data/mc2.rds')\n} else {\n   MC2 <- fromJSON('data/mc2_challenge_graph.json')\n   write_rds(MC2, 'data/mc2.rds')\n}\n```\n:::\n\n\nThen, we convert the data to a \"tidy\" format using `tidygraph` methods, excluding unneeded columns at the same time. (Note: there's a discrepancy between the data dictionary and data --- there's no `type` attribute found in the edges data.)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nMC2_nodes <- as_tibble(MC2$nodes) %>%\n  select(!dataset) \n\nMC2_edges <- as_tibble(MC2$links) %>%\n  select(!dataset)\n```\n:::\n\n\nNext, we double-check the columns and correct data types as necessary.\n\n-   We discover that there is an additional attribute in edges, named `valueofgoodsusd`, which we will leave in place for now.\n\n-   The edge attribute `arrivaldate` has been interpreted as a `char` type. Let's change it to a `date` type:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nMC2_edges %<>% mutate(arrivaldate = ymd(arrivaldate))\n```\n:::\n\n\n-   The HS Codes appear problematic. According to online research, the first 6 digits of HS Code should be consistent across countries, while the subsequent digits may differ. However, the most common HS code in the data, `306170`, is not even a valid HS code. My suspicion is that there is a missing leading 0, i.e. the correct code is actually `030617` (possibly with subsequent digits). This could have been the result of incorrect data storage/export: the leading 0 may not have been stored, and the export function may have simply extracted the first 6 digits of the data. Using the full list of [HS Codes published by Singapore Customs](https://www.tradenet.gov.sg/tradenet/portlets/search/searchHSCA/searchInitHSCA.do) as a reference, let's examine what HS Codes might be erroneous:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# HS Codes provided by Singapore Customs\ntradenet_hscodes <- read_xls('data/AllHSCode20230527155627.xls')\n\ncode_6d <- tradenet_hscodes %>%\n  transmute(hscode = substring(`HS Code`,1,6)) %>%\n  pull(hscode)\n\nMC2_invalid_hscodes <- MC2_edges %>%\n  select(hscode) %>%\n  group_by(hscode) %>%\n  summarise(cnt = n()) %>%\n  mutate(validcode = hscode %in% code_6d) %>%\n  filter(validcode == FALSE) %>%\n  pull(hscode)\n```\n:::\n\n\nAmong these, since our use case involves fishing, we would be particularly interested in correcting HS Codes related to fish, seafood, etc. From the World Customs Organization website, these would be codes from Chapter 3 (*Fish and crustaceans, molluscs and other aquatic invertebrates*), specifically 0301-0309 (erroneously coded as 301xxx to 309xxx in our data). So let's correct these:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_edges %<>%\n  mutate(hscode_corrected = if_else(hscode %in% MC2_invalid_hscodes & strtoi(substr(hscode,1,3))>=301 & strtoi(substr(hscode,1,3))<=309,\n                                    paste0('0', substr(hscode,1,5)),\n                                    hscode)) %>%\n  select(!hscode) %>%\n  rename(hscode = hscode_corrected)\n```\n:::\n\n\nLet's check for possible duplicate shipment records. We see there are about 100K duplicate shipment records in the dataset. We can remove them when we create the edges for the graph.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nMC2_edges %>%\n  distinct() %>%\n  summarise(n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n    `n()`\n    <int>\n1 5309087\n```\n:::\n:::\n\n\nFinally, we create a tidygraph object from the nodes and edges data, using only fishing-related edges (i.e. starting with 03) and their corresponding nodes:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# reorder columns to what tidygraph expects\nMC2_edges %<>%\n  filter(substr(hscode,1,2)=='03') %>%\n  relocate(source, target) %>%\n  distinct()\n\nMC2_node_ids <- bind_rows(\n  MC2_edges %>% select(id=source),\n  MC2_edges %>% select(id=target)) %>%\n  distinct()\n\nMC2_nodes %<>%\n  filter(id %in% pull(MC2_node_ids,id)) %>%\n  relocate(id)\n\n\nMC2_graph <- tbl_graph(nodes = MC2_nodes,\n                       edges = MC2_edges,\n                       directed = TRUE)\n```\n:::\n\n\nAfter cutting down our data, we are left with about a quarter of the original number of nodes, and a tenth of the original number of edges:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nprint(MC2_nodes %>% summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      id             shpcountry         rcvcountry       \n Length:9048        Length:9048        Length:9048       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n```\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nprint(MC2_edges %>% summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    source             target           arrivaldate         valueofgoods_omu  \n Length:547725      Length:547725      Min.   :2028-01-01   Min.   :    5705  \n Class :character   Class :character   1st Qu.:2029-11-29   1st Qu.:  398655  \n Mode  :character   Mode  :character   Median :2031-09-08   Median :  760180  \n                                       Mean   :2031-08-15   Mean   : 2118449  \n                                       3rd Qu.:2033-05-28   3rd Qu.: 1654955  \n                                       Max.   :2034-12-30   Max.   :44744530  \n                                                            NA's   :547566    \n   volumeteu            weightkg         valueofgoodsusd        hscode         \n Min.   :   0.0000   Min.   :        0   Min.   :        0   Length:547725     \n 1st Qu.:   0.0000   1st Qu.:    18150   1st Qu.:    75905   Class :character  \n Median :   0.0000   Median :    20360   Median :   133075   Mode  :character  \n Mean   :   0.3802   Mean   :    22716   Mean   :   164421                     \n 3rd Qu.:   0.0000   3rd Qu.:    23015   3rd Qu.:   196102                     \n Max.   :1215.0000   Max.   :131710670   Max.   :111432620                     \n NA's   :606                             NA's   :19914                         \n```\n:::\n:::\n\n\n#### Data Completeness\n\nLet's do a check on missing values:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ncolMeans(is.na(MC2_nodes))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        id shpcountry rcvcountry \n 0.0000000  0.3322281  0.1320734 \n```\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\ncolMeans(is.na(MC2_edges))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          source           target      arrivaldate valueofgoods_omu \n     0.000000000      0.000000000      0.000000000      0.999709708 \n       volumeteu         weightkg  valueofgoodsusd           hscode \n     0.001106395      0.000000000      0.036357661      0.000000000 \n```\n:::\n:::\n\n\nHere, we can see that some attributes have a very high proportion of missing values: `shpcountry` (33%) and `valueofgoods_omu` (99.9%). Let's just bear this in mind for now.\n\n# Exploratory Data Analysis\n\n## Entities\n\n### Companies\n\nOf the companies, about 30% (2,797) do not have a name, only an ID number:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_nodes %>%\n  select(id) %>%\n  distinct() %>%\n  filter(str_detect(id, regex(r\"(-\\d+$)\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,797 × 1\n   id    \n   <chr> \n 1 -1143 \n 2 -6894 \n 3 -12516\n 4 -1515 \n 5 -193  \n 6 -54   \n 7 -21759\n 8 -214  \n 9 -987  \n10 -754  \n# ℹ 2,787 more rows\n```\n:::\n:::\n\n\n### Countries\n\nLet's see which countries appear most frequently ship to, and receive shipments from, Oceanus. First, count the countries:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_nodes_shpToOceanus <- MC2_nodes %>%\n  filter(shpcountry!='Oceanus' & rcvcountry=='Oceanus') %>%\n  group_by(shpcountry) %>%\n  filter(!is.na(shpcountry)) %>%\n  summarise(count = n())\n\nMC2_nodes_rcvFrOceanus <- MC2_nodes %>%\n  filter(shpcountry=='Oceanus' & rcvcountry!='Oceanus') %>%\n  group_by(rcvcountry) %>%\n  filter(!is.na(rcvcountry)) %>%\n  summarise(count = n())\n\n# unused for now\nMC2_nodes_gathered <- MC2_nodes %>%\n  filter(shpcountry=='Oceanus' | rcvcountry=='Oceanus') %>%\n  gather(\"shprcvcountry\", \"country\", -id, na.rm = TRUE) %>%\n  group_by(country, shprcvcountry) %>%\n  filter(country!='Oceanus') %>%\n  summarise(count=n()) \n  # spread(shprcvcountry, count, fill = 0)\n```\n:::\n\n\nThen, plot the countries:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(slice_max(MC2_nodes_shpToOceanus, order_by = count, n=20),\n       aes(y=fct_reorder(shpcountry, count),\n           x=count)) +\n  geom_col() +\n  scale_x_continuous(name = 'No. of Companies', position='top', limits=c(0,1700), expand=c(0,0)) +\n  scale_y_discrete(name = 'Country') +\n  theme_minimal() +\n  theme(axis.ticks.y=element_blank()) +\n  labs(title = \"Top 20 countries most often exporting to Oceanus\",\n       )\n\np2 <- ggplot(slice_max(MC2_nodes_rcvFrOceanus, order_by = count, n=20, with_ties = FALSE),\n       aes(y=fct_reorder(rcvcountry, count),\n           x=count)) +\n  geom_col() +\n  scale_x_continuous(name = 'No. of Companies', position='top', limits=c(0,17), expand=c(0,0)) +\n  scale_y_discrete(name = 'Country') +\n  theme_minimal() +\n  theme(axis.ticks.y=element_blank()) +\n  labs(title = \"Top 20 countries most often importing from Oceanus\",\n       )\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-13-1.png){width=1152}\n:::\n:::\n\n\nFrom the above graph, we can see that for companies that have Oceanus as their most common receiving country, the most common shipping country is Marebak. On the other hand, for companies that have Oceanus as their most common shipping country, the most common receiving country is Coralmarica. Note the dramatically different x-axis scales: far more most commonly companies ship to Oceanus than receive from Oceanus.\n\n## Shipments\n\n### Number of shipments over time\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(MC2_edges %>% \n         group_by(arrivalmonthyear=floor_date(arrivaldate, unit ='month')) %>% \n         summarise(count = n(), \n                   totalvalue_omu = sum(valueofgoods_omu, na.rm = TRUE),\n                   totalvalue_usd = sum(valueofgoodsusd, na.rm = TRUE)),\n       aes(x=arrivalmonthyear)) +\n  scale_x_date(name = 'Arrival', date_breaks = 'year', date_minor_breaks = 'month', date_labels = '%Y') +\n  scale_y_continuous(name = 'No. of Shipments', labels = scales::comma) +\n  geom_line(aes(y=count)) +\n  # geom_line(aes(y=totalvalue_omu), color='red') +\n  # geom_line(aes(y=totalvalue_usd), color='blue') +\n  labs(title = \"Total number of shipments over time\")\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n### Total value of shipments over time\n\nWe can see that data for the value of shipments in OMU is only available for a short period in 2034-2035. In contrast value of shipments in USD is available throughout the period, and displays seasonality as well as an overall upward trend. The seasonality is probably to be expected since fishing is seasonally affected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(MC2_edges %>% \n         group_by(arrivalmonthyear=floor_date(arrivaldate, unit ='month')) %>% \n         summarise(count = n(), \n                   totalvalue_omu = sum(valueofgoods_omu, na.rm = TRUE),\n                   totalvalue_usd = sum(valueofgoodsusd, na.rm = TRUE)) %>%\n         pivot_longer(c(totalvalue_omu, totalvalue_usd), names_to = \"currency\", values_to = \"valueofgoods\") %>%\n         mutate(valueofgoods = na_if(valueofgoods, 0)),\n       aes(x=arrivalmonthyear,\n           color=currency)) +\n  scale_x_date(name = 'Arrival', date_breaks = 'year', date_minor_breaks = 'month', date_labels = '%Y') +\n  scale_y_sqrt(name = 'Value', labels = scales::label_comma(suffix = \"M\", scale=1e-6)) +\n  geom_line(aes(y=valueofgoods)) +\n  scale_color_discrete(name = 'Currency', labels = c('OMU', 'USD')) +\n  # geom_line(aes(y=count)) +\n  # geom_line(aes(y=totalvalue_omu), color='red') +\n  # geom_line(aes(y=totalvalue_usd), color='blue') +\n  labs(title = \"Total value of shipments over time\",\n       subtitle = \"Note: value axis uses a square-root scale.\")\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n### Relationship between shipment value and size\n\nA log-log plot of shipment value (in USD) against shipment weight (in kg) shows an almost straight line, indicating a power relationship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(MC2_edges %>% drop_na(valueofgoodsusd, weightkg) %>% filter(!valueofgoodsusd==0 & !weightkg==0),\n       aes(x=weightkg,\n           y=valueofgoodsusd)) +\n  geom_point(alpha=0.3) +\n  scale_y_log10() +\n  scale_x_log10()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n### Aggregating Edges\n\nNow let's aggregate the edges (shipments) to reduce the number of edges to work with to a more manageable number:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_edges_agg <- MC2_edges %>%\n  group_by(source,target) %>%\n  summarise(shipment_count = n(),\n            arrivaldate_earliest = min(arrivaldate),\n            arrivaldate_latest = max(arrivaldate))\n\nprint(MC2_edges_agg %>% summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    source             target          shipment_count     arrivaldate_earliest\n Length:35895       Length:35895       Min.   :    1.00   Min.   :2028-01-01  \n Class :character   Class :character   1st Qu.:    1.00   1st Qu.:2028-12-22  \n Mode  :character   Mode  :character   Median :    2.00   Median :2030-07-31  \n                                       Mean   :   15.26   Mean   :2030-11-21  \n                                       3rd Qu.:    8.00   3rd Qu.:2032-08-27  \n                                       Max.   :10876.00   Max.   :2034-12-29  \n arrivaldate_latest  \n Min.   :2028-01-01  \n 1st Qu.:2030-01-09  \n Median :2032-01-09  \n Mean   :2031-12-07  \n 3rd Qu.:2033-12-17  \n Max.   :2034-12-30  \n```\n:::\n:::\n\n\nWe still have close to 36,000 edges after aggregation. Let's examine the distribution of shipment counts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_edges_agg %>%\n  ggplot(aes(x=shipment_count)) +\n  geom_histogram(binwidth=20)\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nClearly, the vast majority of edges have very low shipment counts. Let's eliminate these low-count edges and focus our attention on more 'active' relationships:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_edges_agg %<>%\n  filter(shipment_count > 20)\n\nprint(MC2_edges_agg %>% summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    source             target          shipment_count    arrivaldate_earliest\n Length:4157        Length:4157        Min.   :   21.0   Min.   :2028-01-01  \n Class :character   Class :character   1st Qu.:   29.0   1st Qu.:2028-02-27  \n Mode  :character   Mode  :character   Median :   44.0   Median :2029-01-01  \n                                       Mean   :  101.3   Mean   :2029-08-23  \n                                       3rd Qu.:   88.0   3rd Qu.:2030-10-11  \n                                       Max.   :10876.0   Max.   :2034-11-30  \n arrivaldate_latest  \n Min.   :2028-02-24  \n 1st Qu.:2032-04-18  \n Median :2034-04-29  \n Mean   :2033-06-21  \n 3rd Qu.:2034-11-25  \n Max.   :2034-12-30  \n```\n:::\n:::\n\n\nNow we are left with a much more manageable number of edges, a bit over 4,000.\n\n## Build Graph\n\nLet's re-extract the nodes and build our new graph:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_nodes_extracted <- MC2_nodes %>%\n    filter(id %in% MC2_edges_agg$source | id %in% MC2_edges_agg$target)\n\nMC2_graph_agg <- tbl_graph(nodes = MC2_nodes_extracted,\n                           edges = MC2_edges_agg,\n                           directed = TRUE)\n```\n:::\n\n\nA first visual look at the resulting graph:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_graph_agg %>%\n  ggraph(layout='fr') +\n  geom_edge_link(aes(width=shipment_count),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.5,5)) +\n  geom_node_point(size=1) +\n  theme_graph()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nRightaway, we can see that there is one large connected component in the centre, and many other smaller disconnected components (each of 2-3 nodes). To focus our attention on the largest component, let's extract just that:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_graph_agg %<>%\n  activate(nodes) %>%\n  mutate(group = group_components()) %>%\n  filter(group==1)\n```\n:::\n\n\nLet's see how the graph looks like now:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_graph_agg %>%\n ggraph(layout='stress') +\n  geom_edge_link(aes(width=shipment_count),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.5,5)) +\n  geom_node_point(size=1, color='lightblue') +\n  theme_graph()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nFrom here on out, we'll only use this subset of nodes and edges for analysis.\n\n# Network Analysis\n\n## Centrality\n\nIn networks, it's common to look at the centrality of nodes as it gives a sense of which nodes are 'important' in a network. There are different measures of centrality. Let's generate centrality statistics for the following:\n\n-   Degree: both in-degree and out-degree, with both unweighted and weighted variants (reflects number of counterparties and direction/total volume of shipments)\n\n-   Betweenness (reflects the importance that nodes play as 'bridges' between different parts of the network)\n\n-   Eigenvector (reflects importance, based on whether other important nodes connect to it)\n\nWe also calculate the ratio of out-degree to in-degree: this will help us characterise whether a company is more of a sender or receiver.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_graph_agg %<>%\n  activate(nodes) %>%\n  mutate(deg_o = centrality_degree(mode='out'),\n         wdeg_o = centrality_degree(weights=shipment_count, mode='out'),\n         deg_i = centrality_degree(mode='in'),\n         wdeg_i = centrality_degree(weights=shipment_count, mode='in'),\n         deg_oi_ratio = (deg_o+1)/(deg_i+1),\n         wdeg_oi_ratio = (wdeg_o+1)/(wdeg_i+1),\n         betweenness = centrality_betweenness(normalized = TRUE),\n         eigen = centrality_eigen(weights=shipment_count))\n\ncentralities <- MC2_graph_agg %>%\n  activate(nodes) %>%\n  as_tibble()\n```\n:::\n\n\n### Top companies by different centrality measures\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_centralities <- MC2_graph_agg %>%\n  activate(nodes) %>%\n  as_tibble() %>%\n  pivot_longer(c(deg_o, wdeg_o, deg_i, wdeg_i, betweenness, eigen), names_to='centrality_type', values_to='centrality_value') %>%\n  group_by(centrality_type) %>%\n  top_n(10, centrality_value) %>%\n  ungroup() %>%\n  mutate(r = reorder_within(id, centrality_value, centrality_type))\n\nggplot(top_centralities, aes(x=fct_reorder(r, centrality_value), y=centrality_value, fill=id)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~centrality_type, scales = 'free') +\n  scale_x_reordered(name = \"Companies\") +\n  scale_y_continuous(name = 'Centrality Value') +\n  coord_flip() +\n  labs(title = \"Top 10 Companies by various centrality measures\")\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-25-1.png){width=1920}\n:::\n:::\n\n\nAs we would expect, these companies with high centrality scores are generally located in the centre of the network when we draw the network graph using a stress layout:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_graph_agg %>%\n  # activate(edges) %>%\n  # filter(shipment_count >200) %>%\n  activate(nodes) %>%\n  mutate(top10_centrality = ifelse(id %in% top_centralities$id, 'Yes', 'No')) %>%\n  # mutate(component = group_components()) %>%\n  filter(group_components()==1) %>%\n ggraph(layout='stress') +\n  geom_edge_link(aes(width=shipment_count),\n                 alpha=0.2) +\n  scale_edge_width(name = 'No. of shipments', range = c(0.5,5)) +\n  geom_node_point(aes(fill=log10(deg_oi_ratio), color=top10_centrality, size=top10_centrality), shape=21, stroke=1) +\n  # scale_size(range = c(1,5)) +\n  # scale_color_discrete(name = 'Top 10 Centrality', direction=-1) +\n  scale_fill_continuous_diverging(palette='Blue-Red 3', guide='none', l1=30, l2=100, p1=0.9, p2=1.2) +\n  scale_size_manual(name = 'Top 10 Centrality', values=c('Yes'=5,'No'=2)) +\n  scale_color_manual(name = 'Top 10 Centrality', values=c('transparent', 'black')) +\n  theme_graph() +\n  labs(title = \"Graph of shipments\",\n       subtitle = \"Colour indicates whether company mostly sends (red) or receives (blue).\\nHigh centrality nodes are indicated by larger size and black border.\")\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-26-1.png){width=1920}\n:::\n:::\n\n\n# Temporal Analysis\n\n## Operating Timelines of Source Companies\n\nIt was mentioned in the challenge that *\"companies caught fishing illegally will shut down but will then often start up again under a different name\"*. Here, I tried to plot the operating timelines of the companies to see if such temporal patterns can be detected. I made an assumption that in such situations, the old and new companies would be similar in scale (shipment values or volumes). Hence I put time on the x-axis and 'operation scale' (average) on the y-axis so that companies of similar scale would appear closer together. To avoid clutter, I only plotted the start and end months of operations, each with a different shape. Hence, proximity of two different shapes at roughly the same vertical height could indicate the described pattern.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource_monthly_agg <- MC2_edges %>%\n  group_by(source,\n           arrivalmonthyear=floor_date(arrivaldate, unit ='month')) %>% \n  summarise(count = n(),\n            totalvalue_omu = sum(valueofgoods_omu, na.rm = TRUE),\n            totalvalue_usd = sum(valueofgoodsusd, na.rm = TRUE),\n            totalweight_kg = sum(weightkg, na.rm = TRUE),\n            avgvalue_omu = mean(valueofgoods_omu, na.rm = TRUE),\n            avgvalue_usd = mean(valueofgoodsusd, na.rm = TRUE),\n            avgweight_kg = mean(weightkg, na.rm = TRUE))\n\nsource_earliest_latest <- source_monthly_agg %>%\n  group_by(source) %>%\n  summarise(arrivalmonthyear_earliest = min(arrivalmonthyear),\n            arrivalmonthyear_latest = max(arrivalmonthyear)) %>%\n  pivot_longer(c(arrivalmonthyear_earliest, arrivalmonthyear_latest),\n               names_to = 'arrivalmonthyear_type',\n               values_to = 'arrivalmonthyear')\n\nsource_agg_earliest_latest <- source_monthly_agg %>%\n  inner_join(source_earliest_latest,\n              by = join_by(source, arrivalmonthyear)) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsource_agg_earliest_latest %>%\n  filter(avgweight_kg < 20e6) %>%\nggplot(aes(x=arrivalmonthyear,\n           y=avgweight_kg,\n           group=source,\n           color=source)) +\n  geom_line(alpha=0.1) +\n  geom_point(aes(shape=arrivalmonthyear_type)) +\n  # geom_point(data=source_agg_earliest_latest) +\n  scale_x_date(name = 'Arrival', date_breaks = 'year', date_minor_breaks = 'month', date_labels = '%Y') +\n  scale_y_continuous(name = 'Average Shipment Weight (kg)',  labels = scales::label_comma(suffix = \"M\", scale=1e-6)) +\n  scale_color_discrete(guide='none') +\n  scale_shape_manual(name = 'Event', labels = c('First Shipment', 'Last Shipment'), values = c(1,4)) +\n  facet_wrap(~ cut_number(avgweight_kg, 6), ncol = 1, scales = 'free')\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-28-1.png){width=1920}\n:::\n\n```{.r .cell-code}\n  # theme(legend.position = 'none')\n```\n:::\n\n\n## Day-of-Week Activity\n\nHere, I wondered if companies who engage in illegal fishing might be trying to do so on certain days of the week with less shipments to lessen the chance of getting caught. Hence, I decided to examine the number of companies operating shipments by days of the week:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_edges %>%\n  mutate(weekday = wday(arrivaldate, week_start = 1, label = TRUE)) %>%\n  mutate(year = year(arrivaldate)) %>%\n  group_by(weekday) %>%\n  summarise(shipments = n_distinct(source)) %>%\n  ggplot(aes(y=weekday,\n             x=shipments)) +\n  geom_col() +\n  scale_y_discrete(name = 'Day of Week') +\n  scale_x_continuous(name = 'Number of companies') +\n  labs(title = \"Number of companies operating by day of week\",\n       subtitle = \"There are overall fewer shipments on 'Wed' and 'Thu' compared to other days\")\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nIt seems that there are fewer companies operating on 'Wed' and 'Thu' compared to the other days of the week. (Note that since the dates given in the data are fictitious, it might not really be Wed and Thu; they could well be Sat and Sun, i.e. the weekend.)\n\n## High-Centrality Nodes\n\nLet's examine the temporal patterns of the high-centrality nodes in greater detail.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshipment_send <- MC2_edges %>%\n  group_by(source,\n           arrivalmonthyear=floor_date(arrivaldate, unit ='month')) %>%\n  summarise(shipment_count = n(),\n            totalvalue_usd = sum(valueofgoodsusd, na.rm = TRUE),\n            totalweight_kg = sum(weightkg, na.rm = TRUE)) %>%\n  mutate(shipment_count_type = 'send') %>%\n  rename(id = source)\n\nshipment_receive <- MC2_edges %>%\n  group_by(target,\n           arrivalmonthyear=floor_date(arrivaldate, unit ='month')) %>%\n  summarise(shipment_count = n(),\n            totalvalue_usd = sum(valueofgoodsusd, na.rm = TRUE),\n            totalweight_kg = sum(weightkg, na.rm = TRUE)) %>%\n  mutate(shipment_count_type = 'receive') %>%\n  rename(id = target)\n\n# test3 <- test %>%\n#   full_join(test2,\n#             by = join_by(source==target, arrivalmonthyear==arrivalmonthyear))\n\nshipment_all <- union(shipment_send, shipment_receive)\n```\n:::\n\n### High Betweenness\n\nWe can see something interesting with the nodes having the top 5 betweenness centrality. They all consistently send and receive shipments throughout the months, so may be playing roles as **forwarders** or **transshipment providers**. The differences between number of shipments sent and received are fairly big. Two of them receive a lot more shipments than they send, while the third is the opposite.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_ids <- top_centralities %>%\n  filter(centrality_type=='betweenness') %>%\n  top_n(3, centrality_value) %>%\n  pull(id)\n\nshipment_all %>% \n  filter(id %in% top_ids) %>%\n  ggplot(aes(x=arrivalmonthyear,\n             y=shipment_count)) +\n  geom_line(aes(colour=id, linetype=shipment_count_type)) +\n  scale_x_date(name = 'Arrival', date_breaks = 'year', date_minor_breaks = 'month', date_labels = '%Y') +\n  scale_colour_discrete() +\n  labs(title = \"Shipments sent and received over time by top 3 companies with highest betweenness\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-31-1.png){width=1440}\n:::\n:::\n\n\n### High In-Degree\n\nIn contrast with the high betweenness nodes, the top 3 companies with highest in-degree almost only exclusively receive shipments. This profile suggests they may be **wholesalers** or **purchasers**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_ids <- top_centralities %>%\n  filter(centrality_type=='wdeg_i') %>%\n  top_n(3, centrality_value) %>%\n  pull(id)\n\nshipment_all %>% \n  filter(id %in% top_ids) %>%\n  ggplot(aes(x=arrivalmonthyear,\n             y=shipment_count)) +\n  geom_line(aes(colour=id, linetype=shipment_count_type)) +\n  scale_x_date(name = 'Arrival', date_breaks = 'year', date_minor_breaks = 'month', date_labels = '%Y') +\n  scale_colour_discrete() +\n  labs(title = \"Shipments sent and received over time for top 3 companies with highest in-degree\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-32-1.png){width=1440}\n:::\n:::\n\n\n### High Out-Degree\n\nAs expected, the opposite is observed from the top 3 companies with highest out-degree: they almost only exclusively send shipments (except for one, which had a very low volume of receiving shipments during 2028-2033). This profile suggests they may be the actual **fishing companies**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_ids <- top_centralities %>%\n  filter(centrality_type=='wdeg_o') %>%\n  top_n(3, centrality_value) %>%\n  pull(id)\n\nshipment_all %>% \n  filter(id %in% top_ids) %>%\n  ggplot(aes(x=arrivalmonthyear,\n             y=shipment_count)) +\n  geom_line(aes(colour=id, linetype=shipment_count_type)) +\n  scale_x_date(name = 'Arrival', date_breaks = 'year', date_minor_breaks = 'month', date_labels = '%Y') +\n  scale_colour_discrete() +\n  labs(title = \"Shipments sent and received over time for top 3 companies with highest out-degree\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-33-1.png){width=1440}\n:::\n:::\n\n\n### High Eigenvector Centrality\n\nOf the top 3 companies with highest eigenvector centrality, two are the same as top 3 with highest out-degree. No immediate inferences can be drawn, more study is required.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_ids <- top_centralities %>%\n  filter(centrality_type=='eigen') %>%\n  top_n(3, centrality_value) %>%\n  pull(id)\n\nshipment_all %>% \n  filter(id %in% top_ids) %>%\n  ggplot(aes(x=arrivalmonthyear,\n             y=shipment_count)) +\n  geom_line(aes(colour=id, linetype=shipment_count_type)) +\n  scale_x_date(name = 'Arrival', date_breaks = 'year', date_minor_breaks = 'month', date_labels = '%Y') +\n  scale_colour_discrete() +\n  labs(title = \"Shipments sent and received over time for top 3 companies with highest eigenvector centrality\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-34-1.png){width=1440}\n:::\n:::\n\n\n### Day-of-Week Comparison Between High-Centrality Nodes\n\nThis heatmap shows the number of shipments sent and received by high-centrality nodes (on any measure) broken down by days of the week. It distinctly shows that for about 3/4 of the companies, they primarily send or receive but not both. For the remaining companies though, they send and receive roughly the same number of shipments throughout a week.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_ids <- top_centralities %>%\n  pull(id) %>%\n  unique()\n\nsend_weekdays <- MC2_edges %>%\n  mutate(weekday = wday(arrivaldate, week_start = 1, label = TRUE)) %>%\n  filter(source %in% top_ids) %>%\n  count(source, weekday) %>%\n  arrange(desc(tolower(source)), weekday) %>%\n  mutate(shipment_type = 'send') %>%\n  rename(company = source)\n\nreceive_weekdays <- MC2_edges %>%\n  mutate(weekday = wday(arrivaldate, week_start = 1, label = TRUE)) %>%\n  filter(target %in% top_ids) %>%\n  count(target, weekday) %>%\n  arrange(desc(tolower(target)), weekday) %>%\n  mutate(shipment_type = 'receive') %>%\n  rename(company = target)\n\nsend_receive_weekdays <- union(send_weekdays, receive_weekdays) %>%\n  mutate(across(shipment_type, as.factor))\n\nggplot(send_receive_weekdays,\n       aes(x=weekday, \n           y=fct_inorder(company),\n           fill=n)) +\ngeom_tile(color = \"white\",\n        size = 0.1) +\ncoord_equal() +\nscale_x_discrete(position = 'top') +\nscale_fill_gradient(name = \"# of shipments\",\n                  low = \"light blue\",\n                  high = \"dark blue\") +\ntheme(axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5),\n    legend.title = element_text(size = 8),\n    legend.text = element_text(size = 6)\n    ) +\nlabs(title = \"Number of Shipments Sent/Received by High Centrality Nodes per Day of Week\",\n     subtitle = \"Note: Day of week may not be true value due to use of fictitious dates, but relative order should be correct.\",\n     x = \"Day of Week\",\n     y = \"Company\") +\n  facet_wrap(~fct_rev(shipment_type))\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-35-1.png){width=1440}\n:::\n:::\n\n\n# Other Explorations\n\n## Ego Networks\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_graph_agg %>%\n  convert(to_local_neighborhood,\n          node = which(.N()$id == 'Selous Game Reserve  S.A. de C.V.'),\n          order = 1,\n          mode = 'all') %>%\n  activate(nodes) %>%\n  mutate(color = ifelse(id %in% top_centralities$id, 'high centrality', 'others')) %>%\n  ggraph(layout='fr') +\n  geom_edge_link(aes(width=shipment_count, alpha=..index..),\n                 ) +\n  scale_edge_width(range = c(0.5,5)) +\n  scale_edge_alpha('Edge direction', guide = 'edge_direction') +\n  geom_node_point(aes(size=5, color=color)) +\n  scale_size(range = c(0.5,5)) +\n  theme_graph()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n## Shipments among high centrality nodes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC2_graph_agg %>%\n  activate(nodes) %>%\n  filter(id %in% top_centralities$id) %>%\n  ggraph(layout='stress') +\n  geom_edge_link(aes(width=shipment_count),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.5,5)) +\n  geom_node_point(size=1, color='lightblue') +\n  theme_graph()\n```\n\n::: {.cell-output-display}\n![](take_home_ex_02_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "take_home_ex_02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}